{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "training_data = pd.read_csv(\"../Data/TrainingData.csv\")\n",
    "# from math import e \n",
    "# print(e)\n",
    "\n",
    "\n",
    "class LogisticRegression: \n",
    "    def __init__(self, cut_off_on_fit = True, iterations = 1000 , adjust = 0.01, verbose = False):\n",
    "        self.adjust = adjust \n",
    "        self.iterations = iterations \n",
    "        self.cut_off_on_fit = cut_off_on_fit\n",
    "        self.verbose = verbose\n",
    "\n",
    "\n",
    "    #sigmoid function\n",
    "    def sigmoid_func(self, n): \n",
    "        value = 1/(1 + np.exp(-n))\n",
    "        return value \n",
    "\n",
    "    #loss function \n",
    "    def loss_func(h_value , y_value): \n",
    "        value = 1 - y_value\n",
    "        log_component = np.log(1 - h_value)\n",
    "        y_logged = -y_value * np.log(h_value)\n",
    "        value = y_logged - value * log_component\n",
    "        value = value.mean()\n",
    "        return value \n",
    "\n",
    "    def fit_on(self , x_value): \n",
    "        adjust = np.ones((x_value.shape[0], 1))\n",
    "        return np.concatenate((adjust, x_value), axis = 1)\n",
    "\n",
    "    def fit_bounds(self, x_value, y_value):\n",
    "        if self.cut_off_on_fit: \n",
    "            x_value = self.fit_on(x_value)\n",
    "\n",
    "# loss_func(0.62, 0.77)\n",
    "\n",
    "\n",
    "    def gradient_descent_function(x_value, h_value, y_value):\n",
    "        return np.dot(x_value.T, (h_value - y_value)) / y_value.shape[0]\n",
    "\n",
    "\n",
    "    def training_stage(self, x_value, y_value):\n",
    "        if self.fit_on: \n",
    "            x_value = self.fit_on(x_value)\n",
    "\n",
    "        self.weights = np.zeros(x_value.shape[1])\n",
    "\n",
    "        for i in range(self.iterations): \n",
    "            n = np.dot(x_value, self.weights) \n",
    "            h_value = self.sigmoid_func(n)\n",
    "            m = np.dot(x_value.T, (h_value - y_value)) / y_value.size\n",
    "            self.weights -= self.adjust * m\n",
    "            \n",
    "            if (self.verbose == True and i % 10000 == 0):\n",
    "                z = np.dot(x_value, self.weights)\n",
    "                h = self.sigmoid_func(n)\n",
    "                print(f'loss: {self.loss_func(h_value, y_value )} \\t')\n",
    "    \n",
    "    def prediction_prob_func(self, x_value): \n",
    "        if self.cut_off_on_fit: \n",
    "            x_value = self.fit_on(x_value)\n",
    "\n",
    "        return self.sigmoid_func(np.dot(x_value, self.weights))\n",
    "\n",
    "    def predict(self, x_value, threshold): \n",
    "        return self.prediction_prob_func(x_value) >= threshold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "10\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "#training features\n",
    "features = training_data.drop([\"home_team_name\", \"away_team_name\", \"home_team_goal_count\" ,\"away_team_goal_count\", \"home_team_result\"  ], axis=1)\n",
    "targets = training_data['home_team_result'].values \n",
    "training_features , training_targets = features, targets\n",
    "\n",
    "#testing features\n",
    "testing_data = pd.read_csv(\"../Data/TestingData.csv\")\n",
    "target_from_old_csv  = pd.read_csv('../Data/Dataset.csv')[\"home_team_result\"].tail(16).values\n",
    "\n",
    "test_features = testing_data.drop([\"home_team_name\", \"away_team_name\", \"home_team_goal_count\" ,\"away_team_goal_count\" ], axis=1)\n",
    "test_target = target_from_old_csv\n",
    "testing_features, testing_targets = test_features, test_target\n",
    "\n",
    "\n",
    "lr_from_scratch = LogisticRegression(adjust = 0.001, iterations = 30000)\n",
    "lr_from_scratch.training_stage(training_features, training_targets)\n",
    "\n",
    "prediction_sequence = lr_from_scratch.prediction_prob_func(testing_features)\n",
    "prediction_sequence = prediction_sequence.flatten()\n",
    "\n",
    "# lr_from_scratch.training_stage(training_features, training_targets)\n",
    "\n",
    "# print(prediction_sequence)\n",
    "\n",
    "roundup  = [round(sequence_item) for sequence_item in prediction_sequence]\n",
    "target_predictions = [int(sequence_item) for sequence_item in roundup]\n",
    "\n",
    "print(testing_targets)\n",
    "print(target_predictions)\n",
    "\n",
    "# print(int_values)\n",
    "\n",
    "match = accuracy_score(testing_targets, target_predictions, normalize = False)\n",
    "\n",
    "print(match)\n",
    "\n",
    "percentage = match / 16\n",
    "\n",
    "print(percentage)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
