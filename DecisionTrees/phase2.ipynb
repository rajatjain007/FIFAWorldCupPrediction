{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Implementation with \"Pseudo\" Feature Embedding\n",
    "#Reference: https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/ \n",
    "\n",
    "#Importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node Class\n",
    "#Each node holds feature index, threshold, left and right output, and info gain value\n",
    "class Node():\n",
    "    def __init__(self, featureIndex=None, threshold=None, left=None, right=None, infoGain=None, value=None):\n",
    "        #for decision node\n",
    "        self.featureIndex = featureIndex\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.infoGain = infoGain\n",
    "        \n",
    "        #for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree Class\n",
    "#Include functions that help configure and build a decision tree\n",
    "class DecisionTreeClassifier():\n",
    "\n",
    "    #initializing the tree\n",
    "    def __init__(self,minSamplesSplit,maxDepth): \n",
    "        self.root = None\n",
    "        self.minSamplesSplit = minSamplesSplit\n",
    "        self.maxDepth = maxDepth\n",
    "    \n",
    "    #predict only one data point\n",
    "    def onePrediction(self,x,tree):        \n",
    "        if tree.value != None: \n",
    "\n",
    "            return tree.value\n",
    "        featureVal = x[tree.featureIndex]\n",
    "\n",
    "        if featureVal <= tree.threshold:\n",
    "\n",
    "            return self.onePrediction(x,tree.left)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            return self.onePrediction(x,tree.right)\n",
    "\n",
    "    #test/predict new dataset\n",
    "    def predict(self,X):        \n",
    "        preditions = [self.onePrediction(x,self.root) for x in X]\n",
    "        return preditions\n",
    "\n",
    "    #output leaf node\n",
    "    def calculateLeafValue(self,Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    #output gini value\n",
    "    def getGini(self,y):        \n",
    "        classLabels = np.unique(y)\n",
    "        gini = 0\n",
    "\n",
    "        for cls in classLabels:\n",
    "            pCls = len(y[y == cls]) / len(y)\n",
    "            gini += pCls ** 2\n",
    "\n",
    "        return 1 - gini\n",
    "    \n",
    "    #output entropy value\n",
    "    def entropy(self,y):\n",
    "        classLabels = np.unique(y)\n",
    "        entropy = 0\n",
    "\n",
    "        for cls in classLabels:\n",
    "            pCls = len(y[y == cls]) / len(y)\n",
    "            entropy += -pCls * np.log2(pCls)\n",
    "\n",
    "        return entropy\n",
    "\n",
    "    #output info gain value\n",
    "    def informationGain(self,parent,leftChild,rightChild,mode=\"entropy\"):        \n",
    "        weightLeft = len(leftChild) / len(parent)\n",
    "        weightRight = len(rightChild) / len(parent)\n",
    "\n",
    "        if mode == \"gini\":\n",
    "            gain = self.getGini(parent) - (weightLeft * self.getGini(leftChild) + weightRight * self.getGini(rightChild))\n",
    "        \n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weightLeft * self.entropy(leftChild) + weightRight * self.entropy(rightChild))\n",
    "\n",
    "        return gain\n",
    "\n",
    "    #spliting the data left and right\n",
    "    def split(self,dataset,featureIndex,threshold):\n",
    "        datasetLeft = np.array([row for row in dataset if row[featureIndex] <= threshold])\n",
    "        datasetRight = np.array([row for row in dataset if row[featureIndex] > threshold])\n",
    "\n",
    "        return datasetLeft, datasetRight        \n",
    "\n",
    "    #finding the best split after trying different features and thresholds\n",
    "    def getBestSplit(self,dataset,numFeatures):        \n",
    "        bestSplit = {}\n",
    "        maxInfoGain = -float(\"inf\")\n",
    "        \n",
    "        for featureIndex in range(numFeatures):\n",
    "            featureValues = dataset[:,featureIndex]\n",
    "            possibleThresholds = np.unique(featureValues)\n",
    "\n",
    "            for threshold in possibleThresholds:\n",
    "                datasetLeft, datasetRight = self.split(dataset,featureIndex,threshold)\n",
    "\n",
    "                if len(datasetLeft) > 0 and len(datasetRight) > 0:\n",
    "                    y, leftY, rightY = dataset[:,-1], datasetLeft[:, -1], datasetRight[:,-1]\n",
    "                    currInfoGain = self.informationGain(y,leftY,rightY,\"gini\")\n",
    "                    \n",
    "                    if currInfoGain > maxInfoGain:\n",
    "                        bestSplit[\"featureIndex\"] = featureIndex\n",
    "                        bestSplit[\"threshold\"] = threshold\n",
    "                        bestSplit[\"datasetLeft\"] = datasetLeft\n",
    "                        bestSplit[\"datasetRight\"] = datasetRight\n",
    "                        bestSplit[\"infoGain\"] = currInfoGain\n",
    "                        maxInfoGain = currInfoGain\n",
    "                        \n",
    "        return bestSplit\n",
    "\n",
    "    #Recursion function using other functions to build an optimal tree\n",
    "    def buildTree(self, dataset, currDepth=0):        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        numSamples, numFeatures = np.shape(X)\n",
    "        \n",
    "        if numSamples >= self.minSamplesSplit and currDepth <= self.maxDepth:\n",
    "            bestSplit = self.getBestSplit(dataset, numFeatures)\n",
    "\n",
    "            if bestSplit[\"infoGain\"] > 0:\n",
    "                leftSubtree = self.buildTree(bestSplit[\"datasetLeft\"], currDepth + 1)\n",
    "                rightSubtree = self.buildTree(bestSplit[\"datasetRight\"], currDepth + 1)\n",
    "\n",
    "                return Node(bestSplit[\"featureIndex\"], bestSplit[\"threshold\"], leftSubtree, rightSubtree, bestSplit[\"infoGain\"])\n",
    "        \n",
    "        leafValue = self.calculateLeafValue(Y)\n",
    "\n",
    "        return Node(value=leafValue)\n",
    "\n",
    "    #train decision tree model\n",
    "    def fit(self,X,Y):\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.buildTree(dataset)\n",
    "\n",
    "    #print dicision tree\n",
    "    def printTree(self, tree=None, indent=\" \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"featureIndex X\"+str(tree.featureIndex), \"<=\", tree.threshold, \"? infoGain:\", tree.infoGain)\n",
    "            print(\"%sLeft:\" % (indent), end=\"\")\n",
    "            self.printTree(tree.left, indent + indent)\n",
    "            print(\"%sRight:\" % (indent), end=\"\")\n",
    "            self.printTree(tree.right, indent + indent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and spliting our dataset to training and testing data\n",
    "trainingData = pd.read_csv(\"../Data/TrainingData.csv\")\n",
    "testingData = pd.read_csv(\"../Data/TestingData.csv\")\n",
    "\n",
    "# Training Data \n",
    "targets = trainingData[\"home_team_result\"]\n",
    "targets = targets.values.reshape(-1,1)\n",
    "features = trainingData.drop([\"home_team_name\", \"away_team_name\", \"home_team_goal_count\", \"away_team_goal_count\", \"home_team_result\",\"winner_encoded\"],axis=1).values\n",
    "featuresTrain = features\n",
    "targetsTrain = targets\n",
    "\n",
    "# Testing Data\n",
    "targets = testingData[\"home_team_result\"]\n",
    "targets = targets.values.reshape(-1,1)\n",
    "features = testingData.drop([\"home_team_name\", \"away_team_name\", \"home_team_goal_count\", \"away_team_goal_count\", \"home_team_result\"],axis=1).values\n",
    "featuresTest = features\n",
    "targetsTest = targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  56.25 %\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "dtree = DecisionTreeClassifier(20, 20)\n",
    "dtree.fit(featuresTrain, targetsTrain)\n",
    "\n",
    "#Testing\n",
    "test = dtree.predict(featuresTest) \n",
    "print('Accuracy: ',accuracy_score(targetsTest, test)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureIndex X9 <= 2.0 ? infoGain: 0.10018631436314374\n",
      " Left:1.0\n",
      " Right:featureIndex X10 <= 7.0 ? infoGain: 0.0455988179079273\n",
      "  Left:featureIndex X6 <= 9.0 ? infoGain: 0.08368241770947288\n",
      "    Left:0.0\n",
      "    Right:1.0\n",
      "  Right:0.0\n"
     ]
    }
   ],
   "source": [
    "#print decision tree\n",
    "dtree.printTree()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b80aff2a19cf941dbb44256e5b2c5db4bea0d59041b979103d19485f1a4c9597"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
